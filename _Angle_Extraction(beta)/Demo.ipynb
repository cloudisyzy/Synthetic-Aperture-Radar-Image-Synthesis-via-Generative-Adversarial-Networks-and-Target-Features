{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4984534-219d-4db6-aaa5-c5ae50255b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot convert from object to float64.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 114>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    107\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../_MSTAR/TRAIN/T72/HB03787.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# image = cv2.imread('../_MSTAR/TRAIN/2S1/HB19379.jpeg', cv2.IMREAD_GRAYSCALE)\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# image = cv2.imread('../_MSTAR/TRAIN/BTR60/HB03817.jpeg', cv2.IMREAD_GRAYSCALE)\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# image = cv2.imread('../_MSTAR/TRAIN/D7/HB20012.jpeg', cv2.IMREAD_GRAYSCALE)\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# image = cv2.imread('../_MSTAR/TRAIN/ZSU234/HB19470.jpeg', cv2.IMREAD_GRAYSCALE)\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Step 1: Target segmentation\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m binary_target \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_segmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# Step 2: Edge extraction\u001b[39;00m\n\u001b[0;32m    117\u001b[0m edges \u001b[38;5;241m=\u001b[39m edge_extraction(binary_target)\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mtarget_segmentation\u001b[1;34m(image, max_iterations, lambda1, lambda2, smoothing)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtarget_segmentation\u001b[39m(image, max_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, lambda1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, lambda2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Convert the image to a floating-point format\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mimg_as_float\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Perform level set evolution using the Chan-Vese algorithm\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     ls \u001b[38;5;241m=\u001b[39m segmentation\u001b[38;5;241m.\u001b[39mmorphological_chan_vese(\n\u001b[0;32m     15\u001b[0m         image,\n\u001b[0;32m     16\u001b[0m         num_iter\u001b[38;5;241m=\u001b[39mmax_iterations,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m         smoothing\u001b[38;5;241m=\u001b[39msmoothing\n\u001b[0;32m     21\u001b[0m     )\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\torch2\\lib\\site-packages\\skimage\\util\\dtype.py:477\u001b[0m, in \u001b[0;36mimg_as_float\u001b[1;34m(image, force_copy)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimg_as_float\u001b[39m(image, force_copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;124;03m\"\"\"Convert an image to floating point format.\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \n\u001b[0;32m    454\u001b[0m \u001b[38;5;124;03m    This function is similar to `img_as_float64`, but will not convert\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    475\u001b[0m \n\u001b[0;32m    476\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 477\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloating\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_copy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\torch2\\lib\\site-packages\\skimage\\util\\dtype.py:264\u001b[0m, in \u001b[0;36m_convert\u001b[1;34m(image, dtype, force_copy, uniform)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (dtype_in \u001b[38;5;129;01min\u001b[39;00m _supported_types \u001b[38;5;129;01mand\u001b[39;00m dtype_out \u001b[38;5;129;01min\u001b[39;00m _supported_types):\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot convert from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtypeobj_in\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    265\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtypeobj_out\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kind_in \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mui\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    268\u001b[0m     imin_in \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(dtype_in)\u001b[38;5;241m.\u001b[39mmin\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot convert from object to float64."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import skimage\n",
    "from skimage import segmentation, img_as_float\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "def target_segmentation(image, max_iterations=500, lambda1=1, lambda2=1, smoothing=1):\n",
    "    # Convert the image to a floating-point format\n",
    "    image = img_as_float(image)\n",
    "    \n",
    "    # Perform level set evolution using the Chan-Vese algorithm\n",
    "    ls = segmentation.morphological_chan_vese(\n",
    "        image,\n",
    "        num_iter=max_iterations,\n",
    "        init_level_set=\"checkerboard\",\n",
    "        lambda1=lambda1,\n",
    "        lambda2=lambda2,\n",
    "        smoothing=smoothing\n",
    "    )\n",
    "    \n",
    "    # ls is a boolean numpy array, where True represents the target region\n",
    "    binary_target = ls.astype(np.uint8)\n",
    "    \n",
    "    # Crop the central region of the binary image\n",
    "    return binary_target\n",
    "\n",
    "def edge_extraction(binary_image, neighbor_threshold=10):\n",
    "    # Define a 3x3 neighborhood kernel\n",
    "    kernel = np.ones((3, 3), dtype=np.uint8)\n",
    "    kernel[1, 1] = 0  # Exclude the center pixel\n",
    "    \n",
    "    # Count the number of target pixels in the neighborhood of each pixel\n",
    "    neighbor_count = cv2.filter2D(binary_image, -1, kernel)\n",
    "    \n",
    "    # Create an edge matrix\n",
    "    edges = np.zeros_like(binary_image)\n",
    "    edges[(binary_image == 1) & (neighbor_count < neighbor_threshold)] = 1\n",
    "    \n",
    "    return edges\n",
    "\n",
    "def azimuth_calculation(edges):\n",
    "    # Find the coordinates of edge pixels\n",
    "    coords = np.column_stack(np.where(edges > 0))\n",
    "    \n",
    "    # Check if there are enough points for calculation\n",
    "    if len(coords) < 5:\n",
    "        return None, None  # Not enough points for calculation\n",
    "    \n",
    "    # Calculate the minimum bounding rectangle using OpenCV\n",
    "    rect = cv2.minAreaRect(coords.astype(np.float32))\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "    \n",
    "    # Extract the angle from the rectangle\n",
    "    angle = rect[2]\n",
    "    # OpenCV returns angles in the range [-90, 0)\n",
    "    # Adjust the angle to match the azimuth definition\n",
    "    if angle < -45:\n",
    "        angle = 90 + angle\n",
    "    else:\n",
    "        angle = -angle\n",
    "    \n",
    "    azimuth_angle = angle % 360  # Ensure the angle is in the range [0, 360)\n",
    "    \n",
    "    return azimuth_angle, box\n",
    "\n",
    "def line_detection_and_drawing(binary_target, image):\n",
    "    # Find contours in the segmented image\n",
    "    contours, _ = cv2.findContours(binary_target, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        return image, None  # No contours found, return original image and angle as None\n",
    "\n",
    "    # Select the largest contour\n",
    "    contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Compute the minimum enclosing triangle\n",
    "    area, trgl = cv2.minEnclosingTriangle(contour)\n",
    "    trgl = trgl.astype(int)\n",
    "    \n",
    "    # Use the triangle vertices to define points for line drawing\n",
    "    index_list = [0, 1, 2]\n",
    "    index = np.argmax(trgl[:, :, 1])  # Find the lowest point (largest y-coordinate)\n",
    "    index_list.remove(index)\n",
    "    low_point = trgl[index]\n",
    "    point_A = trgl[index_list[0]]\n",
    "    point_B = trgl[index_list[1]]\n",
    "    len_line_A = np.linalg.norm(point_A - low_point)\n",
    "    len_line_B = np.linalg.norm(point_B - low_point)\n",
    "    target_point = point_A if len_line_A > len_line_B else point_B\n",
    "\n",
    "    # Draw the line on the image\n",
    "    result_img = image.copy()\n",
    "    cv2.line(result_img, tuple(low_point[0]), tuple(target_point[0]), (255, 0, 0), 1)\n",
    "    \n",
    "    # Calculate the angle of the line (0-180 degrees)\n",
    "    delta_y = target_point[0][1] - low_point[0][1]\n",
    "    delta_x = target_point[0][0] - low_point[0][0]\n",
    "    angle = np.degrees(np.arctan2(delta_y, delta_x))\n",
    "    if angle < 0:\n",
    "        angle += 180  # Adjust the angle to the range [0, 180 degrees]\n",
    "    \n",
    "    return result_img, angle\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread('../_MSTAR/TRAIN/T72/HB03787.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "# image = cv2.imread('../_MSTAR/TRAIN/2S1/HB19379.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "# image = cv2.imread('../_MSTAR/TRAIN/BTR60/HB03817.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "# image = cv2.imread('../_MSTAR/TRAIN/D7/HB20012.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "# image = cv2.imread('../_MSTAR/TRAIN/ZSU234/HB19470.jpeg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Step 1: Target segmentation\n",
    "binary_target = target_segmentation(image)\n",
    "\n",
    "# Step 2: Edge extraction\n",
    "edges = edge_extraction(binary_target)\n",
    "\n",
    "# Step 3: Azimuth calculation\n",
    "azimuth_angle, bounding_box = azimuth_calculation(edges)\n",
    "\n",
    "# Step 4: Line detection and angle calculation\n",
    "result_with_line, line_angle = line_detection_and_drawing(binary_target, binary_target)\n",
    "\n",
    "# Output the azimuth angle and line angle\n",
    "print(f\"Azimuth: {line_angle:.2f}°\")\n",
    "\n",
    "# Display the results\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(binary_target, cmap='gray')\n",
    "plt.title('Segmented Target')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(edges, cmap='gray')\n",
    "plt.title('Extracted Edges')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(result_with_line, cmap='gray')\n",
    "plt.title(f'Line Detection\\nAngle: {line_angle:.2f}°')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9511fdb1-e9c1-4165-b640-06d967938f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
